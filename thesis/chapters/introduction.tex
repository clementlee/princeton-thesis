\chapter{Introduction}

Deep learning has exploded in recent years as the forefront of what the New York Times has referred to as the ``A.I. Awakening.'' \cite{aiawakening}.
It has seen applications in 

% why deep nets are better

The promise of deep learning has been ushered in at a pace that has surprised even many within the field.
For example, AlphaGo \cite{silver2016mastering} was able to beat modern Go masters at a game that was generally considered to be an unassailable human stronghold.

The promise of deep learning has come with additional complexities, however.
Typical deep networks, while providing excellent accuracy, have far worse computational efficiency than other methods of machine learning.
AlphaGo was reliant on large-scale distributed computing infrastructure in order to achieve peak performance, and in fact the modern-day superiority of deep networks has often been attributed to a maturity of hardware and technology.
Furthermore, due to the high computational costs of deep networks, developing new architectures is a very slow and costly process involving long wait times.
Combined with a generally confusing literature on ever-changing best practices, deep learning is a research quagmire.
We aim to improve on the current state of network design by making the training process more transparent to the user.